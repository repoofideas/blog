{
  
    
        "post0": {
            "title": "Introducing My Book Reader",
            "content": "Introducing My Book Reader . Due to COVID-19, all of my courses for fall semester turned remote. Due to extreme circumstances, I have decided to temporarily move with my family. At home, my mother is suffering from xerophthalmia, which makes her difficult to see bright lights or screens. Watching her struggle made me research how many people are suffering from vision impairment: according to estimates from WHO, a staggering 2.2 billion have some type of vision impairment and this number is quickly increasing. Now, if you are accustomed to digital format, it is not difficult to have texts read to you. However, if you are like my mother, who collects quite a few books and mostly reads printed books, then vision-impairment is truly devastating. I have tested various text-reading applications in the market, and I have identified common issues: . There is no audio text-reading capabilities | If there is audio text-reading, the reading speed cannot be controlled or you have to rely on other volunteers to help you | UI is not friendly for people with impaired vision | That is where I got inspiration to work on My Book Reader, a mobile app that can read printed text. Please provide feedbacks or PR in my-book-reader if you are interested! Many thanks to KJ Huang for collaborating on this project. .",
            "url": "https://repoofideas.github.io/blog/app%20development/applied%20ml/2020/09/20/Introducing-My-Book-Reader.html",
            "relUrl": "/app%20development/applied%20ml/2020/09/20/Introducing-My-Book-Reader.html",
            "date": " • Sep 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Case for Interpretable Machine Learning",
            "content": "Case for Interpretable Machine Learning . From video recommendation, autonomous vehicles to predictive medicine, machine learning(ML) systems are ubiquitous in decision making process. ML systems are often labeled as black-box models, since their complexity makes it challenging for human evaluation or understanding. Recently, Geoffrey Hinton, one of the founders of deep learning, tweeted the following: . Suppose you have cancer and you have to choose between a black box AI surgeon that cannot explain how it works but has a 90% cure rate and a human surgeon with an 80% cure rate. Do you want the AI surgeon to be illegal? . &mdash; Geoffrey Hinton (@geoffreyhinton) February 20, 2020 This post spurred large discussions about interpretable ML systems and whether explanation for their outputs are necessary. In this scenario, I believe that the scalability and cost will nudge the user’s decision, but that’s a huge topic appropriate for a future post of its own. As pointed out in many interpretability papers1 ML systems for performance does not address important criteria such as nondiscrimination, safety, or right to explanation by end-users or legal systems. Ignoring any of these criteria could lead to alarming consequences, but unlike measures of performance, these criteria are usually difficult to quantify. For example, HR system may discriminate applications based on many confounders that may not be obvious to the recruiter. To address such cases, ML researchers are developing methods to measure interpretability; or the ability to explain ML systems in understandable terms to human. . The attention mechanism in transformers has dramatically improved the performance in wide domains, and it also provides insight for interpretability. The main idea is this: each time the model generates an output, it only refers small part of the input that is most relevant to the output. By quantifying the level of input relevance, users can evaluate which part the data the model is most attentive to. For a more in-depth explanation, check out these great posts Attention? Attention! by Lilian Weng and The Annotated Transformer. Note that the transformers are a variant of attention model that revolutionized natural language processing in recent years. I will post other interesting interpretability probing techniques so stay tuned! . Acknowledgments . References terminologies from ‘Towards A Rigorous Science of Interpretable Machine Learning’ by Finale Doshi-Velez and Been Kim. &#8617; . |",
            "url": "https://repoofideas.github.io/blog/interpretable%20machine%20learning/transformers/2020/03/16/Case-for-Interpretable-Machine-Learning.html",
            "relUrl": "/interpretable%20machine%20learning/transformers/2020/03/16/Case-for-Interpretable-Machine-Learning.html",
            "date": " • Mar 16, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://repoofideas.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Problem Orientation for the Long Term",
            "content": "Problem Orientation for the Long Term . It has been a year since I have enrolled in a computer science graduate program. A lot has changed since then, including my rent price(rip my savings), but there’s one thing I am repeating exactly the same as last year at this period. I am applying to summer internships amid turndowns. Let’s look at a post from the subreddit r/cscareeradvice that describes how internship rejection truly feels. . What you feel, anytime you begin to think about them; That hurt you can’t exactly articulate into words? It’s okay to feel those feelings. It’s okay to hurt. If necessary, it’s okay to cry. You won’t be any less of a person because you’re experiencing strong emotions. . That was actually from r/datingadvice but you can see the analogy! Gratefully, I was able to land a full-time research internship last summer but there was one important lesson which I would like to instill in myself for an optimal, long-term research career. Last year, I was embarrassingly overconfident in few deep learning techniques that I have learned. I have recommended coworkers to apply those techniques without valid justification or understanding of their research problems. As amazing as deep learning is, prioritizing technique itself is short-sighted and easily misguided. . Early this year, I found a book written by Peter Feibelman called ’ A PhD is Not Enough,’ an alarming title for a mere master’s student. I want to quote a great excerpt about problem-orientation. . When a remarkable new instrument, such as the laser, or a technique, like nuclear magnetic resonance spectrometry, becomes available, it is often profitable to ask how its capabilities can be applied to solving outstanding problems. Few scientists, however, are able to make a long-term success of applying their favorite technique to one problem after another. Eventually the well runs dry. It is the researchers who focus on a significant problem and are willing to bring to it whatever resources are necessary who give the most absorbing talks, write the most significant papers, and win grant support most easily. I strongly recommend that you try to teach yourself to be problem-oriented, to plan your research projects so that they address important scientific issues regardless of what techniques you and your coworkers will need to use. . Looking at the number of papers coming out of deep learning community these days, learning the new SOTA technique will not be marketable for much. Without problem-orientation, it may be nearly impossible to survive in this rapidly evolving field and one must steer away from the juicy trap of technique-orientation. .",
            "url": "https://repoofideas.github.io/blog/research%20rants/2020/01/14/Problem-Orientation.html",
            "relUrl": "/research%20rants/2020/01/14/Problem-Orientation.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "",
          "content": "I have recently graduated with a master’s degree in computer science from Stony Brook University and currently looking for full-tiem opportunities. My research at LUNR lab is focused in developing deep-learning based aggregation mechanisms that can prevent inference from combining semantically incompatible evidence. I am also interested in empirical side of designing large scale experiments and evaluating performances of language models. This research project is advised by Prof. Niranjan Balasubramanian and funded by NSF. I have previously worked in projects in domains of computer vision and neuroscience. . If you want to read more about my past projects and experiences, please visit my Linkedin. . I also love to test with multi-modal and user-guided generation. The logo and title font in my front page is generated by AI, and I have modified about 2%(~1200 pixels) of it manually. .",
          "url": "https://repoofideas.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://repoofideas.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}