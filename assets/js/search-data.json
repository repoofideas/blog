{
  
    
        "post0": {
            "title": "How does Amazon recommend products to the users? 🔎",
            "content": "Intro . Before you buy a product, a typical decision process may include comparison of similar products, browsing multiple brands, or consulting an expert(if you are lucky enough to know one). Recommendation systems are designed to simplify these convoluted process, like a personalized consultant. Since Amazon is the largest online retailer in the world, I became interested in how their website tailor personalized recommendations for enormous number of products and users. Upon research, I’ve found an interesting paper1 and patent2 from Rahul Bhagat, an applied scientist at Amazon, that used repeat purchase history and product type for personalized recommendations. . ‘Buy it Again’ recommendaiton feature from Amazon . . ok . Acknowledgments . Bhagat, R., Muralidharan, S., Lobzhanidze, A., &amp; Vishwanath, S. (2018, July). Buy it again: Modeling repeat purchase recommendations. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (pp. 62-70). &#8617; . | MuralidharanRahul, S., Bhagat, R. (2021). Personalized network content generation and redirection according to time intervals between repeated instances of behavior based on entity size (US10891678B1). U.S. Patent and Trademark Office. https://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=10,891,678.PN.&amp;OS=PN/10,891,678&amp;RS=PN/10,891,678 &#8617; . |",
            "url": "https://repoofideas.github.io/blog/recommendation%20system/2021/05/27/How-does-Amazon-recommend-products-to-the-users.html",
            "relUrl": "/recommendation%20system/2021/05/27/How-does-Amazon-recommend-products-to-the-users.html",
            "date": " • May 27, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Introducing My Book Reader",
            "content": "Introducing My Book Reader . Due to COVID-19, all of my courses for fall semester turned remote. Due to extreme circumstances, I have decided to temporarily move with my family. At home, my mother is suffering from xerophthalmia, which makes her difficult to see bright lights or screens. Watching her struggle made me research how many people are suffering from vision impairment: according to estimates from WHO, a staggering 2.2 billion have some type of vision impairment and this number is quickly increasing. Now, if you are accustomed to digital format, it is not difficult to have texts read to you. However, if you are like my mother, who collects quite a few books and mostly reads printed books, then vision-impairment is truly devastating. I have tested various text-reading applications in the market, and I have identified common issues: . There is no audio text-reading capabilities | If there is audio text-reading, the reading speed cannot be controlled or you have to rely on other volunteers to help you | UI is not friendly for people with impaired vision | That is where I got inspiration to work on My Book Reader, a mobile app that can read printed text. Please provide feedbacks or PR in my-book-reader if you are interested! Many thanks to KJ Huang for collaborating on this project. .",
            "url": "https://repoofideas.github.io/blog/app%20development/applied%20ml/2020/09/20/Introducing-My-Book-Reader.html",
            "relUrl": "/app%20development/applied%20ml/2020/09/20/Introducing-My-Book-Reader.html",
            "date": " • Sep 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Case for Interpretable Machine Learning",
            "content": "Case for Interpretable Machine Learning . From video recommendation, autonomous vehicles to predictive medicine, machine learning(ML) systems are ubiquitous in decision making process. ML systems are often labeled as black-box models, since their complexity makes it challenging for human evaluation or understanding. Recently, Geoffrey Hinton, one of the founders of deep learning, tweeted the following: . Suppose you have cancer and you have to choose between a black box AI surgeon that cannot explain how it works but has a 90% cure rate and a human surgeon with an 80% cure rate. Do you want the AI surgeon to be illegal? . &mdash; Geoffrey Hinton (@geoffreyhinton) February 20, 2020 This post spurred large discussions about interpretable ML systems and whether explanation for their outputs are necessary. In this scenario, I believe that the scalability and cost will nudge the user’s decision, but that’s a huge topic appropriate for a future post of its own. As pointed out in many interpretability papers1 ML systems for performance does not address important criteria such as nondiscrimination, safety, or right to explanation by end-users or legal systems. Ignoring any of these criteria could lead to alarming consequences, but unlike measures of performance, these criteria are usually difficult to quantify. For example, HR system may discriminate applications based on many confounders that may not be obvious to the recruiter. To address such cases, ML researchers are developing methods to measure interpretability; or the ability to explain ML systems in understandable terms to human. . The attention mechanism in transformers has dramatically improved the performance in wide domains, and it also provides insight for interpretability. The main idea is this: each time the model generates an output, it only refers small part of the input that is most relevant to the output. By quantifying the level of input relevance, users can evaluate which part the data the model is most attentive to. For a more in-depth explanation, check out these great posts Attention? Attention! by Lilian Weng and The Annotated Transformer. Note that the transformers are a variant of attention model that revolutionized natural language processing in recent years. I will post other interesting interpretability probing techniques so stay tuned! . Acknowledgments . References terminologies from ‘Towards A Rigorous Science of Interpretable Machine Learning’ by Finale Doshi-Velez and Been Kim. &#8617; . |",
            "url": "https://repoofideas.github.io/blog/interpretable%20machine%20learning/transformers/2020/03/16/Case-for-Interpretable-Machine-Learning.html",
            "relUrl": "/interpretable%20machine%20learning/transformers/2020/03/16/Case-for-Interpretable-Machine-Learning.html",
            "date": " • Mar 16, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Problem Orientation for the Long Term",
            "content": "Problem Orientation for the Long Term . It has been a year since I have enrolled in a computer science graduate program. A lot has changed since then, including my rent price(rip my savings), but there’s one thing I am repeating exactly the same as last year at this period. I am applying to summer internships amid turndowns. Let’s look at a post from the subreddit r/cscareeradvice that describes how internship rejection truly feels. . What you feel, anytime you begin to think about them; That hurt you can’t exactly articulate into words? It’s okay to feel those feelings. It’s okay to hurt. If necessary, it’s okay to cry. You won’t be any less of a person because you’re experiencing strong emotions. . That was actually from r/datingadvice but you can see the analogy! Gratefully, I was able to land a full-time research internship last summer but there was one important lesson which I would like to instill in myself for an optimal, long-term research career. Last year, I was embarrassingly overconfident in few deep learning techniques that I have learned. I have recommended coworkers to apply those techniques without valid justification or understanding of their research problems. As amazing as deep learning is, prioritizing technique itself is short-sighted and easily misguided. . Early this year, I found a book written by Peter Feibelman called ’ A PhD is Not Enough,’ an alarming title for a mere master’s student. I want to quote a great excerpt about problem-orientation. . When a remarkable new instrument, such as the laser, or a technique, like nuclear magnetic resonance spectrometry, becomes available, it is often profitable to ask how its capabilities can be applied to solving outstanding problems. Few scientists, however, are able to make a long-term success of applying their favorite technique to one problem after another. Eventually the well runs dry. It is the researchers who focus on a significant problem and are willing to bring to it whatever resources are necessary who give the most absorbing talks, write the most significant papers, and win grant support most easily. I strongly recommend that you try to teach yourself to be problem-oriented, to plan your research projects so that they address important scientific issues regardless of what techniques you and your coworkers will need to use. . Looking at the number of papers coming out of deep learning community these days, learning the new SOTA technique will not be marketable for much. Without problem-orientation, it may be nearly impossible to survive in this rapidly evolving field and one must steer away from the juicy trap of technique-orientation. .",
            "url": "https://repoofideas.github.io/blog/research%20rants/2020/01/14/Problem-Orientation.html",
            "relUrl": "/research%20rants/2020/01/14/Problem-Orientation.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "I have recently graduated with a master’s degree in computer science from Stony Brook University and currently looking for full-tiem opportunities. My research at LUNR lab is focused in developing deep-learning based aggregation mechanisms that can prevent inference from combining semantically incompatible evidence. I am also interested in empirical side of designing large scale experiments and evaluating performances of language models. This research project is advised by Prof. Niranjan Balasubramanian and funded by NSF. I have previously worked in projects in domains of computer vision and neuroscience. . If you want to read more about my past projects and experiences, please visit my Linkedin. . I also love to test with multi-modal and user-guided generation. The logo and title font in my front page is generated by AI, and I have modified about 2%(~1200 pixels) of it manually. .",
          "url": "https://repoofideas.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://repoofideas.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}